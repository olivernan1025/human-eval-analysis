{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anntator agreement rate is 0.5444444444444444\n",
      "human llm agreement rate is 0.4888888888888889\n",
      "human winrate\n",
      "qwen2.5 winrate is 0.45555555555555555 c4ai winrate is 0.4777777777777778 tie rate is 0.06666666666666667\n",
      "llm winrate\n",
      "qwen2.5 winrate is 0.3 c4ai winrate is 0.6777777777777778 tie rate is 0.022222222222222223\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "with open('aya-vision-human-eval-ARABIC_1742921625533_annotation_data.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "ARABIC_human = {}\n",
    "for task in data['tasks']:\n",
    "    sample = {}\n",
    "    order = eval(task['metadata']['order'])\n",
    "    for utterance in task['attempts'][0]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            answer = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    if answer != 'tie':\n",
    "        sample[task['metadata']['id']]  = order[f'model_{answer}'] \n",
    "    else:\n",
    "        sample[task['metadata']['id']] = answer\n",
    "        \n",
    "    ARABIC_human.update(sample)\n",
    "\n",
    "anntator_agreement = []\n",
    "for task in data['tasks']:\n",
    "    for utterance in task['attempts'][0]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            user1 = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    for utterance in task['attempts'][1]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            user2 = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    if user1 == user2:\n",
    "        anntator_agreement.append(1)\n",
    "    else:\n",
    "        anntator_agreement.append(0)\n",
    "\n",
    "print(f\"anntator agreement rate is {sum(anntator_agreement) / len(anntator_agreement)}\")\n",
    "\n",
    "ARABIC_llm = {}\n",
    "mAyaVisionBench = pd.read_json('gs://cohere-command/data/olivernan/multilingual_LMM_vision_winrate_results/mAyaVisionBench/c4ai-aya-vision-8b/c4ai-aya-vision-8b-Qwen2.5-VL-7B-Instruct-mm-outputs.jsonl', lines=True).to_dict(orient='records')\n",
    "for data in mAyaVisionBench:\n",
    "    if data['language'] == 'arb_Arab':\n",
    "        sample = {}\n",
    "        sample[str(data['index'])] = data['decision']\n",
    "        ARABIC_llm.update(sample)\n",
    "\n",
    "mWildVisionBench = pd.read_json('gs://cohere-command/data/olivernan/multilingual_LMM_vision_winrate_results/mWildVisionBench/c4ai-aya-vision-8b/c4ai-aya-vision-8b-Qwen2.5-VL-7B-Instruct-mm-outputs.jsonl', lines=True).to_dict(orient='records')\n",
    "for data in mWildVisionBench:\n",
    "    if data['language'] == 'arb_Arab':\n",
    "        sample = {}\n",
    "        sample[data['question_id']] = data['decision']\n",
    "        ARABIC_llm.update(sample)\n",
    "\n",
    "agrm = []\n",
    "for id, answer in ARABIC_human.items():\n",
    "    if answer == ARABIC_llm[id]:\n",
    "        agrm.append(1)\n",
    "    else:\n",
    "        agrm.append(0)\n",
    "\n",
    "print(f\"human llm agreement rate is {sum(agrm) / len(agrm)}\")\n",
    "\n",
    "# human winrate \n",
    "human_winrate = []\n",
    "for id, answer in ARABIC_human.items():\n",
    "    if answer == 'Qwen2.5-VL-7B-Instruct':\n",
    "        human_winrate.append(1)\n",
    "    elif answer == 'c4ai-aya-vision-8b':\n",
    "        human_winrate.append(2)\n",
    "    else:\n",
    "        human_winrate.append(3)\n",
    "print(\"human winrate\")\n",
    "print(f\"qwen2.5 winrate is {human_winrate.count(1) / len(human_winrate)} c4ai winrate is {human_winrate.count(2) / len(human_winrate)} tie rate is {human_winrate.count(3) / len(human_winrate)}\")\n",
    "\n",
    "# llm winrate\n",
    "llm_winrate = []\n",
    "for id, answer in ARABIC_human.items():\n",
    "    answer = ARABIC_llm[id]\n",
    "    if answer == 'Qwen2.5-VL-7B-Instruct':\n",
    "        llm_winrate.append(1)\n",
    "    elif answer == 'c4ai-aya-vision-8b':\n",
    "        llm_winrate.append(2)\n",
    "    else:\n",
    "        llm_winrate.append(3)\n",
    "print(\"llm winrate\")\n",
    "print(f\"qwen2.5 winrate is {llm_winrate.count(1) / len(llm_winrate)} c4ai winrate is {llm_winrate.count(2) / len(llm_winrate)} tie rate is {llm_winrate.count(3) / len(llm_winrate)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anntator agreement rate is 0.5645161290322581\n",
      "human llm agreement rate is 0.4838709677419355\n",
      "human winrate\n",
      "qwen2.5 winrate is 0.45161290322580644 c4ai winrate is 0.25806451612903225 tie rate is 0.2903225806451613\n",
      "llm winrate\n",
      "qwen2.5 winrate is 0.5161290322580645 c4ai winrate is 0.3064516129032258 tie rate is 0.1774193548387097\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "with open('aya-vision-human-eval-ENGLISH_1742921619169_annotation_data.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "ENGLISH_human = {}\n",
    "for task in data['tasks']:\n",
    "    sample = {}\n",
    "    order = eval(task['metadata']['order'])\n",
    "    for utterance in task['attempts'][0]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            answer = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    if answer != 'tie':\n",
    "        sample[task['metadata']['id']]  = order[f'model_{answer}'] \n",
    "    else:\n",
    "        sample[task['metadata']['id']] = answer\n",
    "    ENGLISH_human.update(sample)\n",
    "\n",
    "anntator_agreement = []\n",
    "for task in data['tasks']:\n",
    "    for utterance in task['attempts'][0]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            user1 = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    for utterance in task['attempts'][1]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            user2 = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    if user1 == user2:\n",
    "        anntator_agreement.append(1)\n",
    "    else:\n",
    "        anntator_agreement.append(0)\n",
    "\n",
    "print(f\"anntator agreement rate is {sum(anntator_agreement) / len(anntator_agreement)}\")\n",
    "\n",
    "ENGLISH_llm = {}\n",
    "mAyaVisionBench = pd.read_json('gs://cohere-command/data/olivernan/multilingual_LMM_vision_winrate_results/mAyaVisionBench/c4ai-aya-vision-8b/c4ai-aya-vision-8b-Qwen2.5-VL-7B-Instruct-mm-outputs.jsonl', lines=True).to_dict(orient='records')\n",
    "for data in mAyaVisionBench:\n",
    "    if data['language'] == 'eng_Latn':\n",
    "        sample = {}\n",
    "        sample[str(data['index'])] = data['decision']\n",
    "        ENGLISH_llm.update(sample)\n",
    "\n",
    "mWildVisionBench = pd.read_json('gs://cohere-command/data/olivernan/multilingual_LMM_vision_winrate_results/mWildVisionBench/c4ai-aya-vision-8b/c4ai-aya-vision-8b-Qwen2.5-VL-7B-Instruct-mm-outputs.jsonl', lines=True).to_dict(orient='records')\n",
    "for data in mWildVisionBench:\n",
    "    if data['language'] == 'eng_Latn':\n",
    "        sample = {}\n",
    "        sample[data['question_id']] = data['decision']\n",
    "        ENGLISH_llm.update(sample)\n",
    "\n",
    "agrm = []\n",
    "for id, answer in ENGLISH_human.items():\n",
    "    if answer == ENGLISH_llm[id]:\n",
    "        agrm.append(1)\n",
    "    else:\n",
    "        agrm.append(0)\n",
    "\n",
    "print(f\"human llm agreement rate is {sum(agrm) / len(agrm)}\")\n",
    "\n",
    "# human winrate \n",
    "human_winrate = []\n",
    "for id, answer in ENGLISH_human.items():\n",
    "    if answer == 'Qwen2.5-VL-7B-Instruct':\n",
    "        human_winrate.append(1)\n",
    "    elif answer == 'c4ai-aya-vision-8b':\n",
    "        human_winrate.append(2)\n",
    "    else:\n",
    "        human_winrate.append(3)\n",
    "print(\"human winrate\")\n",
    "print(f\"qwen2.5 winrate is {human_winrate.count(1) / len(human_winrate)} c4ai winrate is {human_winrate.count(2) / len(human_winrate)} tie rate is {human_winrate.count(3) / len(human_winrate)}\")\n",
    "\n",
    "\n",
    "# llm winrate\n",
    "llm_winrate = []\n",
    "for id, answer in ENGLISH_human.items():\n",
    "    answer = ENGLISH_llm[id]\n",
    "    if answer == 'Qwen2.5-VL-7B-Instruct':\n",
    "        llm_winrate.append(1)\n",
    "    elif answer == 'c4ai-aya-vision-8b':\n",
    "        llm_winrate.append(2)\n",
    "    else:\n",
    "        llm_winrate.append(3)\n",
    "print(\"llm winrate\")\n",
    "print(f\"qwen2.5 winrate is {llm_winrate.count(1) / len(llm_winrate)} c4ai winrate is {llm_winrate.count(2) / len(llm_winrate)} tie rate is {llm_winrate.count(3) / len(llm_winrate)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anntator agreement rate is 0.6846846846846847\n",
      "human llm agreement rate is 0.5855855855855856\n",
      "human winrate\n",
      "qwen2.5 winrate is 0.6306306306306306 c4ai winrate is 0.34234234234234234 tie rate is 0.02702702702702703\n",
      "llm winrate\n",
      "qwen2.5 winrate is 0.5585585585585585 c4ai winrate is 0.36936936936936937 tie rate is 0.07207207207207207\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "with open('aya-vision-human-eval-CHINESE_1742921630996_annotation_data.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "CHINESE_human = {}\n",
    "for task in data['tasks']:\n",
    "    sample = {}\n",
    "    order = eval(task['metadata']['order'])\n",
    "    for utterance in task['attempts'][0]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            answer = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    if answer != 'tie':\n",
    "        sample[task['metadata']['id']]  = order[f'model_{answer}'] \n",
    "    else:\n",
    "        sample[task['metadata']['id']] = answer\n",
    "    CHINESE_human.update(sample)\n",
    "\n",
    "\n",
    "anntator_agreement = []\n",
    "for task in data['tasks']:\n",
    "    for utterance in task['attempts'][0]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            user1 = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    for utterance in task['attempts'][1]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            user2 = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    if user1 == user2:\n",
    "        anntator_agreement.append(1)\n",
    "    else:\n",
    "        anntator_agreement.append(0)\n",
    "\n",
    "print(f\"anntator agreement rate is {sum(anntator_agreement) / len(anntator_agreement)}\")\n",
    "\n",
    "\n",
    "\n",
    "CHINESE_llm = {}\n",
    "mAyaVisionBench = pd.read_json('gs://cohere-command/data/olivernan/multilingual_LMM_vision_winrate_results/mAyaVisionBench/c4ai-aya-vision-8b/c4ai-aya-vision-8b-Qwen2.5-VL-7B-Instruct-mm-outputs.jsonl', lines=True).to_dict(orient='records')\n",
    "for data in mAyaVisionBench:\n",
    "    if data['language'] == 'zho_Hans':\n",
    "        sample = {}\n",
    "        sample[str(data['index'])] = data['decision']\n",
    "        CHINESE_llm.update(sample)\n",
    "\n",
    "mWildVisionBench = pd.read_json('gs://cohere-command/data/olivernan/multilingual_LMM_vision_winrate_results/mWildVisionBench/c4ai-aya-vision-8b/c4ai-aya-vision-8b-Qwen2.5-VL-7B-Instruct-mm-outputs.jsonl', lines=True).to_dict(orient='records')\n",
    "for data in mWildVisionBench:\n",
    "    if data['language'] == 'zho_Hans':\n",
    "        sample = {}\n",
    "        sample[data['question_id']] = data['decision']\n",
    "        CHINESE_llm.update(sample)\n",
    "\n",
    "agrm = []\n",
    "for id, answer in CHINESE_human.items():\n",
    "    if answer == CHINESE_llm[id]:\n",
    "        agrm.append(1)\n",
    "    else:\n",
    "        agrm.append(0)\n",
    "\n",
    "print(f\"human llm agreement rate is {sum(agrm) / len(agrm)}\")\n",
    "\n",
    "# human winrate \n",
    "human_winrate = []\n",
    "for id, answer in CHINESE_human.items():\n",
    "    if answer == 'Qwen2.5-VL-7B-Instruct':\n",
    "        human_winrate.append(1)\n",
    "    elif answer == 'c4ai-aya-vision-8b':\n",
    "        human_winrate.append(2)\n",
    "    else:\n",
    "        human_winrate.append(3)\n",
    "print(\"human winrate\")\n",
    "print(f\"qwen2.5 winrate is {human_winrate.count(1) / len(human_winrate)} c4ai winrate is {human_winrate.count(2) / len(human_winrate)} tie rate is {human_winrate.count(3) / len(human_winrate)}\")\n",
    "\n",
    "\n",
    "# llm winrate\n",
    "llm_winrate = []\n",
    "for id, answer in CHINESE_human.items():\n",
    "    answer = CHINESE_llm[id]\n",
    "    if answer == 'Qwen2.5-VL-7B-Instruct':\n",
    "        llm_winrate.append(1)\n",
    "    elif answer == 'c4ai-aya-vision-8b':\n",
    "        llm_winrate.append(2)\n",
    "    else:\n",
    "        llm_winrate.append(3)\n",
    "print(\"llm winrate\")\n",
    "print(f\"qwen2.5 winrate is {llm_winrate.count(1) / len(llm_winrate)} c4ai winrate is {llm_winrate.count(2) / len(llm_winrate)} tie rate is {llm_winrate.count(3) / len(llm_winrate)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
