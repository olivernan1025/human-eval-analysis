{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anntator agreement rate is 0.6043478260869565\n",
      "human llm agreement rate is 0.5347826086956522\n",
      "human winrate\n",
      "qwen2.5 winrate is 0.41304347826086957 c4ai winrate is 0.4782608695652174 tie rate is 0.10869565217391304\n",
      "llm winrate\n",
      "qwen2.5 winrate is 0.30869565217391304 c4ai winrate is 0.6478260869565218 tie rate is 0.043478260869565216\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "with open('aya-vision-human-eval-ARABIC_1742921625533_annotation_data.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "ARABIC_human = {}\n",
    "for task in data['tasks']:\n",
    "    sample = {}\n",
    "    order = eval(task['metadata']['order'])\n",
    "    for utterance in task['attempts'][0]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            answer = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    if answer != 'tie':\n",
    "        sample[task['metadata']['id']]  = order[f'model_{answer}'] \n",
    "    else:\n",
    "        sample[task['metadata']['id']] = answer\n",
    "        \n",
    "    ARABIC_human.update(sample)\n",
    "\n",
    "anntator_agreement = []\n",
    "for task in data['tasks']:\n",
    "    for utterance in task['attempts'][0]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            user1 = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    for utterance in task['attempts'][1]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            user2 = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    if user1 == user2:\n",
    "        anntator_agreement.append(1)\n",
    "    else:\n",
    "        anntator_agreement.append(0)\n",
    "\n",
    "print(f\"anntator agreement rate is {sum(anntator_agreement) / len(anntator_agreement)}\")\n",
    "\n",
    "ARABIC_llm = {}\n",
    "mAyaVisionBench = pd.read_json('gs://cohere-command/data/olivernan/multilingual_LMM_vision_winrate_results/mAyaVisionBench/c4ai-aya-vision-8b/c4ai-aya-vision-8b-Qwen2.5-VL-7B-Instruct-mm-outputs.jsonl', lines=True).to_dict(orient='records')\n",
    "for data in mAyaVisionBench:\n",
    "    if data['language'] == 'arb_Arab':\n",
    "        sample = {}\n",
    "        sample[str(data['index'])] = data['decision']\n",
    "        ARABIC_llm.update(sample)\n",
    "\n",
    "mWildVisionBench = pd.read_json('gs://cohere-command/data/olivernan/multilingual_LMM_vision_winrate_results/mWildVisionBench/c4ai-aya-vision-8b/c4ai-aya-vision-8b-Qwen2.5-VL-7B-Instruct-mm-outputs.jsonl', lines=True).to_dict(orient='records')\n",
    "for data in mWildVisionBench:\n",
    "    if data['language'] == 'arb_Arab':\n",
    "        sample = {}\n",
    "        sample[data['question_id']] = data['decision']\n",
    "        ARABIC_llm.update(sample)\n",
    "\n",
    "agrm = []\n",
    "for id, answer in ARABIC_human.items():\n",
    "    if answer == ARABIC_llm[id]:\n",
    "        agrm.append(1)\n",
    "    else:\n",
    "        agrm.append(0)\n",
    "\n",
    "print(f\"human llm agreement rate is {sum(agrm) / len(agrm)}\")\n",
    "\n",
    "# human winrate \n",
    "human_winrate = []\n",
    "for id, answer in ARABIC_human.items():\n",
    "    if answer == 'Qwen2.5-VL-7B-Instruct':\n",
    "        human_winrate.append(1)\n",
    "    elif answer == 'c4ai-aya-vision-8b':\n",
    "        human_winrate.append(2)\n",
    "    else:\n",
    "        human_winrate.append(3)\n",
    "print(\"human winrate\")\n",
    "print(f\"qwen2.5 winrate is {human_winrate.count(1) / len(human_winrate)} c4ai winrate is {human_winrate.count(2) / len(human_winrate)} tie rate is {human_winrate.count(3) / len(human_winrate)}\")\n",
    "\n",
    "# llm winrate\n",
    "llm_winrate = []\n",
    "for id, answer in ARABIC_human.items():\n",
    "    answer = ARABIC_llm[id]\n",
    "    if answer == 'Qwen2.5-VL-7B-Instruct':\n",
    "        llm_winrate.append(1)\n",
    "    elif answer == 'c4ai-aya-vision-8b':\n",
    "        llm_winrate.append(2)\n",
    "    else:\n",
    "        llm_winrate.append(3)\n",
    "print(\"llm winrate\")\n",
    "print(f\"qwen2.5 winrate is {llm_winrate.count(1) / len(llm_winrate)} c4ai winrate is {llm_winrate.count(2) / len(llm_winrate)} tie rate is {llm_winrate.count(3) / len(llm_winrate)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anntator agreement rate is 0.5454545454545454\n",
      "human llm agreement rate is 0.45454545454545453\n",
      "human winrate\n",
      "qwen2.5 winrate is 0.4954545454545455 c4ai winrate is 0.2409090909090909 tie rate is 0.2636363636363636\n",
      "llm winrate\n",
      "qwen2.5 winrate is 0.4909090909090909 c4ai winrate is 0.36363636363636365 tie rate is 0.14545454545454545\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "with open('aya-vision-human-eval-ENGLISH_1742921619169_annotation_data.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "ENGLISH_human = {}\n",
    "for task in data['tasks']:\n",
    "    sample = {}\n",
    "    order = eval(task['metadata']['order'])\n",
    "    for utterance in task['attempts'][0]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            answer = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    if answer != 'tie':\n",
    "        sample[task['metadata']['id']]  = order[f'model_{answer}'] \n",
    "    else:\n",
    "        sample[task['metadata']['id']] = answer\n",
    "    ENGLISH_human.update(sample)\n",
    "\n",
    "anntator_agreement = []\n",
    "for task in data['tasks']:\n",
    "    for utterance in task['attempts'][0]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            user1 = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    for utterance in task['attempts'][1]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            user2 = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    if user1 == user2:\n",
    "        anntator_agreement.append(1)\n",
    "    else:\n",
    "        anntator_agreement.append(0)\n",
    "\n",
    "print(f\"anntator agreement rate is {sum(anntator_agreement) / len(anntator_agreement)}\")\n",
    "\n",
    "ENGLISH_llm = {}\n",
    "mAyaVisionBench = pd.read_json('gs://cohere-command/data/olivernan/multilingual_LMM_vision_winrate_results/mAyaVisionBench/c4ai-aya-vision-8b/c4ai-aya-vision-8b-Qwen2.5-VL-7B-Instruct-mm-outputs.jsonl', lines=True).to_dict(orient='records')\n",
    "for data in mAyaVisionBench:\n",
    "    if data['language'] == 'eng_Latn':\n",
    "        sample = {}\n",
    "        sample[str(data['index'])] = data['decision']\n",
    "        ENGLISH_llm.update(sample)\n",
    "\n",
    "mWildVisionBench = pd.read_json('gs://cohere-command/data/olivernan/multilingual_LMM_vision_winrate_results/mWildVisionBench/c4ai-aya-vision-8b/c4ai-aya-vision-8b-Qwen2.5-VL-7B-Instruct-mm-outputs.jsonl', lines=True).to_dict(orient='records')\n",
    "for data in mWildVisionBench:\n",
    "    if data['language'] == 'eng_Latn':\n",
    "        sample = {}\n",
    "        sample[data['question_id']] = data['decision']\n",
    "        ENGLISH_llm.update(sample)\n",
    "\n",
    "agrm = []\n",
    "for id, answer in ENGLISH_human.items():\n",
    "    if answer == ENGLISH_llm[id]:\n",
    "        agrm.append(1)\n",
    "    else:\n",
    "        agrm.append(0)\n",
    "\n",
    "print(f\"human llm agreement rate is {sum(agrm) / len(agrm)}\")\n",
    "\n",
    "# human winrate \n",
    "human_winrate = []\n",
    "for id, answer in ENGLISH_human.items():\n",
    "    if answer == 'Qwen2.5-VL-7B-Instruct':\n",
    "        human_winrate.append(1)\n",
    "    elif answer == 'c4ai-aya-vision-8b':\n",
    "        human_winrate.append(2)\n",
    "    else:\n",
    "        human_winrate.append(3)\n",
    "print(\"human winrate\")\n",
    "print(f\"qwen2.5 winrate is {human_winrate.count(1) / len(human_winrate)} c4ai winrate is {human_winrate.count(2) / len(human_winrate)} tie rate is {human_winrate.count(3) / len(human_winrate)}\")\n",
    "\n",
    "\n",
    "# llm winrate\n",
    "llm_winrate = []\n",
    "for id, answer in ENGLISH_human.items():\n",
    "    answer = ENGLISH_llm[id]\n",
    "    if answer == 'Qwen2.5-VL-7B-Instruct':\n",
    "        llm_winrate.append(1)\n",
    "    elif answer == 'c4ai-aya-vision-8b':\n",
    "        llm_winrate.append(2)\n",
    "    else:\n",
    "        llm_winrate.append(3)\n",
    "print(\"llm winrate\")\n",
    "print(f\"qwen2.5 winrate is {llm_winrate.count(1) / len(llm_winrate)} c4ai winrate is {llm_winrate.count(2) / len(llm_winrate)} tie rate is {llm_winrate.count(3) / len(llm_winrate)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anntator agreement rate is 0.5732758620689655\n",
      "human llm agreement rate is 0.5431034482758621\n",
      "human winrate\n",
      "qwen2.5 winrate is 0.5172413793103449 c4ai winrate is 0.3275862068965517 tie rate is 0.15517241379310345\n",
      "llm winrate\n",
      "qwen2.5 winrate is 0.5086206896551724 c4ai winrate is 0.40086206896551724 tie rate is 0.09051724137931035\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "with open('aya-vision-human-eval-CHINESE_1742921630996_annotation_data.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "CHINESE_human = {}\n",
    "for task in data['tasks']:\n",
    "    sample = {}\n",
    "    order = eval(task['metadata']['order'])\n",
    "    for utterance in task['attempts'][0]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            answer = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    if answer != 'tie':\n",
    "        sample[task['metadata']['id']]  = order[f'model_{answer}'] \n",
    "    else:\n",
    "        sample[task['metadata']['id']] = answer\n",
    "    CHINESE_human.update(sample)\n",
    "\n",
    "\n",
    "anntator_agreement = []\n",
    "for task in data['tasks']:\n",
    "    for utterance in task['attempts'][0]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            user1 = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    for utterance in task['attempts'][1]['conversation']['utterances']:\n",
    "        if utterance['origin'] == 'BOT':\n",
    "            user2 = utterance['annotations'][0]['answers']['preference_decision']\n",
    "    if user1 == user2:\n",
    "        anntator_agreement.append(1)\n",
    "    else:\n",
    "        anntator_agreement.append(0)\n",
    "\n",
    "print(f\"anntator agreement rate is {sum(anntator_agreement) / len(anntator_agreement)}\")\n",
    "\n",
    "\n",
    "\n",
    "CHINESE_llm = {}\n",
    "mAyaVisionBench = pd.read_json('gs://cohere-command/data/olivernan/multilingual_LMM_vision_winrate_results/mAyaVisionBench/c4ai-aya-vision-8b/c4ai-aya-vision-8b-Qwen2.5-VL-7B-Instruct-mm-outputs.jsonl', lines=True).to_dict(orient='records')\n",
    "for data in mAyaVisionBench:\n",
    "    if data['language'] == 'zho_Hans':\n",
    "        sample = {}\n",
    "        sample[str(data['index'])] = data['decision']\n",
    "        CHINESE_llm.update(sample)\n",
    "\n",
    "mWildVisionBench = pd.read_json('gs://cohere-command/data/olivernan/multilingual_LMM_vision_winrate_results/mWildVisionBench/c4ai-aya-vision-8b/c4ai-aya-vision-8b-Qwen2.5-VL-7B-Instruct-mm-outputs.jsonl', lines=True).to_dict(orient='records')\n",
    "for data in mWildVisionBench:\n",
    "    if data['language'] == 'zho_Hans':\n",
    "        sample = {}\n",
    "        sample[data['question_id']] = data['decision']\n",
    "        CHINESE_llm.update(sample)\n",
    "\n",
    "agrm = []\n",
    "for id, answer in CHINESE_human.items():\n",
    "    if answer == CHINESE_llm[id]:\n",
    "        agrm.append(1)\n",
    "    else:\n",
    "        agrm.append(0)\n",
    "\n",
    "print(f\"human llm agreement rate is {sum(agrm) / len(agrm)}\")\n",
    "\n",
    "# human winrate \n",
    "human_winrate = []\n",
    "for id, answer in CHINESE_human.items():\n",
    "    if answer == 'Qwen2.5-VL-7B-Instruct':\n",
    "        human_winrate.append(1)\n",
    "    elif answer == 'c4ai-aya-vision-8b':\n",
    "        human_winrate.append(2)\n",
    "    else:\n",
    "        human_winrate.append(3)\n",
    "print(\"human winrate\")\n",
    "print(f\"qwen2.5 winrate is {human_winrate.count(1) / len(human_winrate)} c4ai winrate is {human_winrate.count(2) / len(human_winrate)} tie rate is {human_winrate.count(3) / len(human_winrate)}\")\n",
    "\n",
    "\n",
    "# llm winrate\n",
    "llm_winrate = []\n",
    "for id, answer in CHINESE_human.items():\n",
    "    answer = CHINESE_llm[id]\n",
    "    if answer == 'Qwen2.5-VL-7B-Instruct':\n",
    "        llm_winrate.append(1)\n",
    "    elif answer == 'c4ai-aya-vision-8b':\n",
    "        llm_winrate.append(2)\n",
    "    else:\n",
    "        llm_winrate.append(3)\n",
    "print(\"llm winrate\")\n",
    "print(f\"qwen2.5 winrate is {llm_winrate.count(1) / len(llm_winrate)} c4ai winrate is {llm_winrate.count(2) / len(llm_winrate)} tie rate is {llm_winrate.count(3) / len(llm_winrate)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
